# Trajan v1.0 Network

type MLP
error_fn "Sum-squared"
no_layers 3

layer 1
no_units 16
width 1
act_fn "(null)"
psp_fn "Linear"
0.559204
0.596985
-0.928467
-0.681885
-0.217407
0.0609131
-0.631226
-0.40448
-0.166565
0.494873
0.792603
-0.350952
-0.178284
-0.0135498
-0.891174
0.66925

layer 2
no_units 16
width 1
act_fn "Logistic"
psp_fn "Linear"
-0.562683
-0.293762
0.966553
0.717102
-0.820068
-0.705444
-0.494873
-0.171814
0.80072
0.662537
0.390198
-0.966064
0.543701
0.710388
0.559875
0.632263
weights 1
0.820496	-0.482239	-0.535278	-0.998352	-0.616455	-0.938782	-0.426453	-0.459045	
0.568298	-0.618042	-0.628601	0.175964	0.648926	-0.515259	-0.165405	-0.276855	
0.709106	0.643005	0.644165	0.785583	-0.699097	0.947693	-0.614014	-0.0244751	
-0.642395	-0.687378	-0.0266724	0.9375	-0.451843	0.874756	0.979675	0.609863	
-0.740112	0.726135	-0.430969	0.161987	-0.601501	-0.0839233	-0.28833	-0.955322	
0.191284	0.659424	0.37207	-0.408203	0.18219	0.690125	0.357788	0.609741	
-0.394653	-0.303711	-0.485107	-0.607483	0.325439	-0.22467	0.959778	0.600891	
-0.46814	0.845581	0.0325928	-0.558472	-0.626038	0.952759	0.661377	-0.415161	
-0.274353	0.408386	0.82373	-0.741638	0.266113	-0.302185	-0.206238	-0.0463257	
-0.935364	0.0951538	0.861389	-0.816101	-0.143433	0.922852	0.211975	-0.270447	
-0.801392	0.393127	-0.346069	0.810242	-0.310181	-0.0308838	-0.119324	-0.380493	
0.447449	-0.816956	-0.0437622	0.660583	-0.976685	0.848877	-0.289978	-0.679871	
-0.050293	-0.393066	0.730286	-0.881531	0.101196	-0.261963	0.641663	-0.927917	
0.0609131	-0.815186	0.356384	0.60791	-0.322449	-0.282349	0.984741	0.464966	
-0.997925	0.182129	0.0939331	-0.977234	0.789978	0.766724	0.00170898	0.491943	
-0.241821	-0.773132	-0.20752	0.406616	0.782898	-0.995911	-0.255676	0.85437	
-0.773499	0.176758	-0.1474	0.882446	-0.418945	-0.819336	-0.860352	0.516724	
-0.384827	0.23645	-0.563354	-0.167908	0.212952	0.421631	0.325867	-0.489197	
0.0914307	-0.675354	0.930176	0.326355	-0.415588	-0.781433	-0.761658	-0.00897217	
0.680359	0.691467	0.652344	0.804199	-0.498291	-0.328247	0.445374	0.538635	
0.412964	0.7854	-0.182861	0.00286865	-0.0546875	0.982361	0.234436	-0.283325	
-0.275024	0.370667	-0.255615	-0.862671	0.59314	0.194458	-0.0521851	0.87439	
-0.895081	0.894409	-0.679688	-0.670044	0.594116	0.187378	-0.431396	0.202271	
-0.00720215	0.103638	0.709045	0.290344	0.591492	0.917847	-0.443115	0.036499	
-0.0714111	0.912781	-0.687073	0.244995	0.996338	-0.0878296	0.935364	-0.586304	
-0.0496216	-0.47937	-0.0159912	-0.88324	0.510986	0.00836182	-0.374573	-0.124451	
0.243103	0.777527	-0.515381	0.954956	0.902588	0.348511	-0.966919	0.523621	
0.0368042	0.802734	-0.801575	-0.385437	0.0262451	0.620728	0.88501	0.324036	
-0.244812	0.851379	0.0914307	-0.31366	-0.901245	0.551514	0.314148	-0.338074	
-0.58606	0.431885	-0.0772095	0.676208	0.221863	0.647949	-0.803833	-0.853455	
-0.730774	-0.327148	0.705811	0.435181	0.155823	0.189636	-0.265198	-0.334473	
0.716187	0.940613	0.418945	-0.161194	0.342712	0.471313	0.29834	-0.310242	

layer 3
no_units 2
width 1
act_fn "Logistic"
psp_fn "Linear"
-0.149353
-0.642578
weights 2
-0.490967	-0.908447	-0.670959	-0.682861	0.562317	0.0111694	-0.160767	-0.349121	
-0.502686	-0.518311	-0.268738	0.337708	0.639954	-0.0269775	-0.271973	-0.265198	
0.0817871	-0.605225	-0.185181	0.039917	0.729553	0.347778	-0.294922	0.591553	
0.358337	0.583191	-0.72168	-0.279297	0.85675	0.605408	-0.320984	-0.409973	

normalisation
classify_by confidence
accept 0.95
reject 0.05
input_normalisation "None"
output_normalisation "None"
input_scaling "Minimax"
input_sf1 0
input_sf2 1
output_scaling "Minimax"
output_sf1 0
output_sf2 1
factors
1	0	1
2	0	1
3	0	1
4	0	1
5	0	1
6	0	1
7	0	1
8	0	1
9	0	1
10	0	1
11	0	1
12	0	1
13	0	1
14	0	1
15	0	1
16	0	1
17	0	1
18	0	1


