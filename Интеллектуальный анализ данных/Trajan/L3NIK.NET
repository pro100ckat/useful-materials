# Trajan v1.0 Network

type MLP
error_fn "Sum-squared"
no_layers 3

layer 1
no_units 9
width 1
act_fn "(null)"
psp_fn "Linear"
-0.39801
-0.167603
0.967041
0.759277
-0.572205
0.039978
0.665161
-0.440308
-0.614502

layer 2
no_units 58
width 1
act_fn "Logistic"
psp_fn "Linear"
0.203103
0.193408
0.868301
0.200935
-0.780597
-0.0809845
0.272769
-0.149368
-0.460032
-0.632157
-0.209231
-0.930105
0.231466
-0.437958
0.878042
0.149868
0.161375
0.145226
-1.16667
0.0933147
0.308853
-0.342022
-0.0321949
-0.0522298
0.477603
-0.256772
0.832595
-0.360157
-0.338382
-0.750623
0.0312095
0.373736
0.125254
-0.0764973
-0.732899
-0.551869
0.176257
0.265243
0.10382
0.725683
0.764666
0.65982
-0.302816
-1.06218
0.506838
0.269092
-0.0615229
0.558299
-0.283514
-0.343455
0.308244
-0.0140031
0.378413
0.710477
-0.532805
-0.496414
0.560456
-0.587635
weights 1
0.604917	-0.425898	0.431893	0.41719	0.467895	-0.608093	-0.398729	-0.938206	
0.141895	
-0.0011153	-0.240875	0.717554	-0.547027	-1.04237	0.237305	0.0160868	0.263728	
1.15522	
0.359408	-0.818035	0.727782	0.530018	0.336684	0.0983887	0.818295	-0.00468651	
-0.482911	
0.633779	-0.389581	0.840261	0.476812	0.909112	-0.224487	0.762375	-0.761104	
0.76262	
0.940142	0.48715	0.0735106	0.487637	0.0570572	-0.441101	-0.243454	-0.613049	
-0.0554481	
-0.468903	0.707225	0.137497	0.347428	-1.12148	0.556335	0.472358	1.23756	
-0.617131	
-0.506767	-0.393858	-0.0726303	-0.442876	1.42939	0.975342	-0.824717	1.14841	
-1.2147	
1.09098	-0.501554	-0.098869	-1.47904	0.314847	-0.570068	-0.650987	-0.910966	
0.555373	
-0.814635	0.687564	0.735719	0.00616547	0.177335	0.83551	0.0546139	1.37663	
-1.45919	
0.405056	1.14656	-0.171273	0.0878527	-0.421818	-0.503784	-0.0502414	-0.992425	
-0.0734511	
0.356121	-0.966011	0.00515598	0.454655	0.216452	0.886047	-1.30683	0.927357	
-1.45399	
0.322688	-0.44699	-1.11928	-0.528822	-0.751662	0.696716	1.53299	0.311034	
0.0204203	
0.424658	-0.591723	-0.618289	-0.180747	-0.0447148	0.389771	0.905667	-0.691006	
0.82388	
0.163872	-0.0976131	-0.180123	-1.11002	0.194656	0.990662	-0.997933	0.661957	
0.593742	
-0.0893605	0.14429	-0.424379	-0.332685	-0.568793	-0.564697	0.372606	0.397897	
-0.870007	
-0.827602	-1.61942	0.442191	-1.07997	0.657701	0.3479	0.484663	0.10061	
1.08649	
-0.140392	-0.561653	-0.138744	-0.401441	0.659437	0.83374	1.38556	-1.74578	
-0.0469254	
0.731335	-0.217792	0.792859	0.494737	0.566075	0.953552	-0.800899	0.885379	
0.344356	
0.0524031	0.202711	-0.804328	-1.18377	-0.430384	-0.495422	-0.171607	-0.0589985	
-1.07534	
-0.127035	0.463172	-1.23169	-0.310293	0.159958	0.647095	1.58761	-0.372817	
1.52322	
0.603703	-0.663808	-0.318462	-1.17965	0.000962601	-0.544189	-0.165022	-0.406805	
0.831175	
0.466094	-1.00841	0.186078	1.22371	-1.29448	0.966553	-1.25559	1.19725	
0.65978	
-0.65201	0.761115	-0.369662	0.383145	0.0635521	0.767334	0.199516	-0.260571	
-0.41242	
0.21746	-0.378075	0.265392	0.103089	-0.781062	0.48468	0.593969	-0.394164	
0.712254	
0.817	0.555097	-0.160778	-0.982789	0.74007	-0.371216	-1.04066	-0.768121	
0.540367	
-0.351465	0.726014	-0.175933	-1.592	0.995929	0.659241	-0.0635474	-1.36767	
0.609169	
-1.00854	1.52447	0.302307	0.79118	0.582713	0.723694	1.6116	-0.472275	
0.517337	
0.780981	0.326904	0.660132	0.000720564	0.20972	-0.576111	0.633466	0.112022	
-0.646258	
-1.11113	-0.0330325	-1.07908	-0.117156	0.624733	0.330933	0.0369323	0.0875103	
0.851822	
-0.341414	-0.618737	-0.168619	-0.532451	0.932868	-0.532471	0.224807	-0.1718	
-0.167589	
0.479886	-0.543482	-0.0700025	-0.958651	-0.0379518	-0.307129	-1.17536	1.5676	
-1.28254	
-1.02431	1.28056	-1.22317	0.477656	-0.00372859	-0.156311	-0.770897	0.669903	
-1.21196	
-0.260277	0.142548	1.03633	0.818377	-0.234322	0.718079	-0.53703	0.0489287	
0.552448	
0.174314	0.194235	-0.338637	-0.842993	-0.681773	-0.541504	0.385304	-0.86997	
-0.490813	
0.492061	-1.19906	-0.662031	-0.077858	0.524577	-0.800903	-0.528982	0.559461	
-0.995845	
0.111984	1.20097	-0.337868	-0.111558	0.131893	-0.632324	0.0536782	-0.988542	
1.13053	
1.19789	-0.263595	1.05253	0.354896	-1.10801	-0.31604	-1.17446	0.530299	
-0.739573	
0.574569	0.70039	0.922709	0.671482	-1.37045	-0.0906982	-0.598649	0.702673	
-0.638627	
0.934177	-0.924583	0.90366	0.358191	-0.992067	0.19043	0.611193	0.866708	
0.707385	
0.389636	-0.109844	0.485766	-1.01491	0.179104	0.764709	0.360601	0.53133	
-0.277521	
0.531093	-0.146051	-0.305953	0.640818	-0.0506446	-0.653748	-0.416938	1.49087	
0.317498	
0.0601708	0.161514	1.01785	-0.943638	0.0946219	-0.672546	-0.920686	-0.72947	
0.24196	
-0.863917	-0.684731	0.121696	0.559903	0.483609	0.526917	-0.0242887	0.82338	
-0.19246	
0.765399	-0.484926	0.658466	0.885616	-0.229098	-0.489319	0.263994	-0.780907	
0.444045	
0.585824	0.26357	0.476142	-0.920087	1.20469	0.395935	0.287321	-0.702037	
-0.809579	
1.05221	-1.86887	0.652265	-0.233117	1.24127	-0.399902	-0.61851	-0.73546	
-0.221435	
-1.38924	1.51951	0.202779	-1.08659	0.229978	0.175354	-1.086	-0.405577	
-0.0170412	
0.33368	0.431908	-0.691096	1.21002	0.0213315	0.197021	-0.330505	0.134511	
0.356324	
0.170842	-1.09294	1.59626	-0.160234	-0.690796	0.247498	-1.23386	0.122868	
0.309951	
-0.429915	1.78743	-0.578623	0.294613	0.0500075	-0.0406494	-0.296238	-0.56315	
0.815341	
-0.731074	1.45496	-0.904231	-0.944278	0.0810986	-0.450989	-0.620223	0.217346	
-0.568161	
-1.54727	1.06626	-0.149273	-0.570259	-0.0996585	-0.0248413	0.0733296	0.0323725	
-0.748547	
-0.695518	1.00383	-0.0880879	-0.694266	0.195756	-0.0727539	0.32586	-0.302594	
-0.115691	
-0.547214	-0.260058	0.822903	-0.396763	0.477865	-0.547913	-0.0754866	-1.27351	
0.960327	
-0.860213	1.07925	-0.522679	-0.353077	0.110118	-0.57074	-0.271642	-0.583515	
0.682179	
0.383254	-1.22496	-1.09841	-0.710655	-0.0409991	0.222961	0.935262	-0.913205	
0.392221	
-0.650681	1.49075	-0.481089	-0.228223	-0.231313	0.637695	-0.825657	1.01393	
0.419245	
0.421206	-0.190221	-0.781118	-0.92716	0.172629	-0.399475	-0.330686	1.39636	
-1.80559	

layer 3
no_units 4
width 1
act_fn "Logistic"
psp_fn "Linear"
0.113576
0.534933
0.387529
-0.217554
weights 2
0.0459869	0.357177	0.474245	-0.491925	-0.119686	-1.31271	-0.866503	1.30331	
-1.32295	-0.0963318	-0.78122	0.804236	0.760215	0.186613	0.306141	1.13916	
1.99072	-0.662521	-0.825277	1.33645	0.792352	-1.29654	-0.560032	0.834003	
0.185407	1.18201	0.451997	0.430016	-0.187552	0.458402	-1.5269	-0.63343	
0.0724545	-0.22892	0.370478	0.620124	-0.756392	-2.02554	-1.07646	0.75588	
-1.37861	0.322162	-0.972773	-0.879202	0.81495	1.39273	-0.806417	-1.14646	
-0.68735	-0.715758	-0.797676	-0.131537	-0.187527	0.846901	0.511757	1.34698	
-1.43007	-1.6383	
-0.424516	0.0796889	0.407438	-0.163559	0.414633	-0.662744	1.59491	0.288034	
0.912582	-1.05985	2.20338	-1.04456	-0.997797	0.556609	0.703532	-0.224794	
-0.945584	-0.0407636	-0.399248	-2.20244	0.275528	0.597648	-0.75585	-0.378565	
0.155259	-0.953196	-2.2576	-0.545044	-1.59446	-0.0651173	1.49352	-1.39001	
-0.0030196	-0.931108	0.71953	-0.954792	1.68499	-0.199047	0.618837	0.680849	
0.296013	0.809058	0.274567	-0.258691	-0.0463586	1.76986	-0.601656	-0.977823	
1.07559	-1.90223	-0.722897	-1.04171	-1.43477	0.0485305	-0.842385	-0.503191	
-0.577784	1.5191	
-1.32615	-1.2021	-0.718143	-1.05176	-0.420782	-0.175739	0.899493	-0.323415	
-0.658445	0.401328	0.848224	-0.0365829	-0.399981	0.0328741	-0.101653	-1.15583	
-0.147815	-0.0917208	0.670767	0.0185533	-0.453039	-1.19645	1.23233	-0.499798	
0.0675778	0.704019	0.476162	-0.365508	0.0836503	-0.0255758	0.903505	1.4697	
-0.410975	-0.28658	0.40087	0.66546	-1.26791	-1.08057	-1.23855	-0.10024	
-0.0483927	0.0387226	0.17103	-0.612751	-0.245583	-1.17785	1.69447	-0.707308	
-1.83619	0.505201	1.83945	1.72115	-0.0030096	-1.03334	1.46073	0.353375	
1.7908	0.0957034	
-0.388801	0.452212	-0.201345	-0.525432	0.155912	1.22462	-1.78059	-1.47616	
-0.160714	0.516868	-0.105131	0.615842	0.0555137	-0.858459	-0.0885662	-1.18303	
-0.947561	0.122178	-1.44119	0.147424	-1.03001	0.967871	0.720164	0.873248	
-1.24298	-1.82062	0.653844	-0.326252	-1.32202	-1.26551	-1.34767	-1.10293	
1.14775	0.139725	-0.848812	0.82107	0.159213	1.53203	1.1594	0.312223	
0.898585	-0.93805	-0.164833	1.08233	-0.838181	-1.69433	-0.781797	0.141547	
-0.896021	0.821427	-0.791133	-0.30841	-0.102175	-1.26952	0.527966	-1.16089	
0.520379	-1.22468	

normalisation
classify_by confidence
accept 0.95
reject 0.05
input_normalisation "None"
output_normalisation "None"
input_scaling "Minimax"
input_sf1 0
input_sf2 1
output_scaling "Minimax"
output_sf1 0
output_sf2 1
factors
1	0	1
2	0	1
3	0	1
4	0	1
5	0	1
6	0	1
7	0	1
8	0	1
9	0	1
10	0	1
11	0	1
12	0	1
13	0	1


