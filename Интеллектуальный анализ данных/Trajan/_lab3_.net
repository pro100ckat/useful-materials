# Trajan v1.0 Network

type MLP
error_fn "Sum-squared"
no_layers 3

layer 1
no_units 16
width 1
act_fn "(null)"
psp_fn "Linear"
-0.133972
-0.935181
0.61322
0.258118
-0.986267
0.22583
0.732666
0.450317
0.761841
-0.907227
-0.880493
0.342407
0.503357
0.0562744
-0.625427
0.16925

layer 2
no_units 16
width 1
act_fn "Logistic"
psp_fn "Linear"
-0.488985
0.812388
0.0593398
-1.138
0.5237
-0.137503
0.215327
0.336086
0.424225
0.82367
-0.18827
0.257717
-0.245152
-0.248846
0.715181
0.450576
weights 1
-1.17741	0.491871	1.74776	-0.232596	0.460133	-0.501571	0.0705369	-0.221802	
1.23885	-0.127301	-0.654746	-0.944214	-0.876393	0.71691	0.0778368	-0.398914	
0.195994	-0.82582	-0.405722	-0.845447	0.153628	0.988411	-0.930555	0.278564	
0.787827	-0.31011	-0.928907	0.706116	0.426827	1.05896	0.023722	0.886117	
0.923095	1.03279	-0.00451751	-0.223448	0.159013	0.637012	-0.997529	0.371887	
0.326119	1.17027	-0.647492	-0.328247	-0.87272	1.33728	-0.318194	-0.524885	
-0.3233	0.615755	0.824735	-0.726621	0.152439	-1.40775	-0.496683	0.216675	
-0.430082	0.0838294	-0.707255	-0.493225	-0.2084	0.69257	0.0610325	-0.0317649	
1.12874	-0.315718	-0.606758	0.830697	1.00772	-0.36445	-0.186745	-0.540039	
0.620483	-0.228461	-0.709508	0.691223	-1.02658	1.86541	0.244955	-0.750572	
-1.08156	0.577797	-0.566659	-0.851275	-0.838646	-0.464906	0.753673	0.986877	
0.329517	-0.501283	1.01172	0.380676	0.978933	-0.235191	-0.421463	1.25207	
-0.666565	-0.273291	-0.111849	-0.87738	1.12481	-0.0357908	-1.07925	0.670837	
0.810933	-0.62667	-0.414997	0.156677	0.778483	-0.250192	1.22624	0.870585	
-0.722427	0.734187	0.402515	0.810898	-0.432924	0.137499	0.731056	-0.876282	
-0.47632	-0.0180181	-0.353599	-0.223572	0.0204786	-1.33485	-0.382082	0.974274	
1.16984	0.404331	-0.619444	1.33384	0.342258	0.431119	0.0706335	-0.554504	
0.299533	0.0102818	-1.01055	0.923096	0.103012	0.697338	0.332638	0.479053	
1.00906	-0.797554	-0.254668	-0.061439	-0.0499349	0.737641	-0.0497946	0.974487	
0.803276	0.598054	0.219369	0.955383	0.212588	-0.139695	-0.114815	-0.613767	
0.804612	1.12134	0.591518	-0.570327	0.402194	-0.219533	-0.395014	-0.962708	
-0.600984	-1.34691	-0.146298	0.65802	-0.570121	0.186903	-0.296808	-0.112114	
-0.776666	0.227497	-0.630388	-0.18395	-1.23176	-0.0357154	0.984148	0.698853	
0.696369	-0.297617	0.811358	-0.00872803	0.448743	-0.797226	-0.760455	1.0865	
-1.4812	-0.547188	0.0651955	0.24018	-1.03241	0.262843	1.02495	0.512207	
-0.657601	-1.22099	0.686877	-0.15863	0.817644	-1.59366	-0.160955	1.23579	
0.220393	0.32578	-0.510767	-0.332831	0.500634	-1.07345	0.920756	0.26886	
0.752526	-0.869357	1.0181	-0.229797	0.343065	-0.714628	-0.685014	0.144334	
0.501597	1.27675	0.749499	1.25318	-0.24576	-0.703942	-0.900517	0.748596	
0.415986	0.0324485	0.265496	-0.234375	-0.264702	0.344639	0.142507	-1.17835	
1.49269	-0.089502	-1.57529	0.658133	-0.726338	1.59192	-0.083973	-0.530701	
-0.831745	0.576979	0.503495	-0.00897217	-0.592845	-0.107203	-0.852687	-0.723521	

layer 3
no_units 2
width 1
act_fn "Logistic"
psp_fn "Linear"
-0.518827
0.965127
weights 2
2.66218	-0.0182514	-0.781869	1.94126	-0.468758	0.219083	1.93598	-0.056414	
-1.80782	-1.03637	1.4589	-0.77337	0.348725	0.440345	0.840484	-3.8072	
0.782591	0.646237	1.97964	-0.0451441	2.82363	-1.88478	0.532217	-1.24223	
1.13639	0.321115	0.0305724	-2.2043	-3.12571	-1.15701	1.52383	0.909429	

normalisation
classify_by confidence
accept 0.95
reject 0.05
input_normalisation "None"
output_normalisation "None"
input_scaling "Minimax"
input_sf1 0
input_sf2 1
output_scaling "Minimax"
output_sf1 0
output_sf2 1
factors
1	0	1
2	0	1
3	0	1
4	0	1
5	0	1
6	0	1
7	0	1
8	0	1
9	0	1
10	0	1
11	0	1
12	0	1
13	0	1
14	0	1
15	0	1
16	0	1
17	0	1
18	0	1


